{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from toy_samples import gaussian_samples\n",
    "from covariance import logX_mu, logX_covinv_chol, points_at_iteration, logPr\n",
    "\n",
    "# Load test samples\n",
    "from tools import pickle_in\n",
    "samples_g_1, samples_c_1, samples_w_1 = pickle_in(\"test_samples/samples_1.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy problem where underlying X distribution is exactly a multivariate Gaussian\n",
    "\n",
    "Test whether approach to maximise logPr gives a better answer than least squares - it does. Tried for y = ax^2 and y = log(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_func(x, theta):\n",
    "    return np.log(theta*x)\n",
    "\n",
    "def log_inverse(y, theta):\n",
    "    return 1/theta * np.exp(y)\n",
    "\n",
    "\n",
    "def linear_func(x, theta):\n",
    "    return theta * x\n",
    "\n",
    "def linear_inverse(y, theta):\n",
    "    return y / theta\n",
    "\n",
    "def logL_func(logX, theta):\n",
    "    d = theta\n",
    "    X = np.exp(logX)\n",
    "    return - X**(2/d)\n",
    "\n",
    "def logX_func(logL, theta):\n",
    "    d = theta\n",
    "    return d/2 * np.log(-logL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def optimise_pr_general(y, inverse, mean, cov_inv, x0):\n",
    "    def negative_prob(theta):\n",
    "        x = inverse(y, theta)\n",
    "        return (x - mean).T @ cov_inv @ (x - mean) # want to maximise probability <-> minimise negative\n",
    "    solution = minimize(negative_prob, x0)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_repeat(mean, cov, func, funcinverse, theta_actual, theta0, covinv=None, repeats=10):\n",
    "    if covinv is None:\n",
    "        covinv = np.linalg.inv(cov)\n",
    "    cg = []\n",
    "    ls = []\n",
    "    for i in range(repeats):\n",
    "        x_actual = np.random.multivariate_normal(mean, cov)\n",
    "        y = func(x_actual, theta_actual)\n",
    "        a_cg, = optimise_pr_general(y, funcinverse, mean, covinv, theta0).x\n",
    "        a_ls, = optimise_pr_general(y, funcinverse, mean, np.eye(len(mean)), theta0).x\n",
    "        cg.append(a_cg)\n",
    "        ls.append(a_ls)\n",
    "    return np.array(cg), np.array(ls)\n",
    "\n",
    "def optimise_repeat_stats(cg, ls):\n",
    "    print(f\"CG: {cg.mean():.4f} +/- {cg.std():.4f}\")\n",
    "    print(f\"LS: {ls.mean():.2f} +/- {ls.std():.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CG does better for random covariances; the larger the covariance, the better it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      weights     \n",
       "1000  8.377862e-11    500\n",
       "1001  8.389654e-11    499\n",
       "1002  8.632691e-11    498\n",
       "1003  8.707837e-11    497\n",
       "1004  8.833418e-11    496\n",
       "                     ... \n",
       "1495  2.368732e-02      5\n",
       "1496  5.353004e-02      4\n",
       "1497  6.201663e-02      3\n",
       "1498  5.825334e-01      2\n",
       "1499  1.000000e+00      1\n",
       "Name: nlive, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from covariance import points_at_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 100\n",
    "mean = np.linspace(100, 200, points)\n",
    "L = np.random.rand(points, points)\n",
    "covrand = L @ L.T\n",
    "covrand = covrand * 1e-4\n",
    "covinvrand = np.linalg.inv(covrand)\n",
    "\n",
    "nk = np.array(points_at_iteration(samples_g_1, 1000)[1000:].nlive)\n",
    "mean_ns = logX_mu(nk)\n",
    "covinv_ns = logX_covinv_chol(nk)\n",
    "cov_ns = np.linalg.inv(covinv_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG: 9.9999 +/- 0.0072\n",
      "LS: 10.29 +/- 0.49\n"
     ]
    }
   ],
   "source": [
    "# Linear function\n",
    "repeats = optimise_repeat(mean_ns, covrand*1e-2, linear_func, linear_inverse, theta_actual=10, theta0=10, covinv=covinvrand, repeats=10)\n",
    "optimise_repeat_stats(*repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73027/3236866486.py:2: RuntimeWarning: invalid value encountered in log\n",
      "  return np.log(theta*x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG: 10.1257 +/- 0.0921\n",
      "LS: 10.36 +/- 1.15\n"
     ]
    }
   ],
   "source": [
    "# Log function\n",
    "repeats = optimise_repeat(mean, covrand*1e6, log_func, log_inverse, theta_actual=10, theta0=10, repeats=10)\n",
    "optimise_repeat_stats(*repeats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CG does worse for NS covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG: 4.9798 +/- 0.1574\n",
      "LS: 10.24 +/- 0.56\n"
     ]
    }
   ],
   "source": [
    "# Using NS mean and covariance matrices\n",
    "repeats = optimise_repeat(mean_ns, cov_ns, logL_func, logX_func, theta_actual=10, theta0=10, covinv=covinv_ns, repeats=10)\n",
    "optimise_repeat_stats(*repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG: 9.7404 +/- 0.1430\n",
      "LS: 3.94 +/- 2.63\n"
     ]
    }
   ],
   "source": [
    "# Keep everything the same except the covariance matrix\n",
    "repeats = optimise_repeat(mean_ns, covrand*10, logL_func, logX_func, theta_actual=10, theta0=10, covinv=covinvrand, repeats=10)\n",
    "optimise_repeat_stats(*repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_actual = 10\n",
    "x_actual = np.random.multivariate_normal(mean, covrand)\n",
    "y = logL_func(x_actual, theta_actual)\n",
    "\n",
    "def negative_prob(theta):\n",
    "    x = logX_func(y, theta)\n",
    "    return (x - mean).T @ covinvrand @ (x - mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b193e973c487348e53c3041550f70cb697f4f9d1473e92be26f2b6259e7d483"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
